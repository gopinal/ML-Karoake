{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing songs from:C:/Users/numbe/Documents/Academics/Coursework/CS 129 - Machine Learning/Final Project/musdb18/test/Vocal Versions\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-b04c149ac7d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_samples_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mgendata_test_vocals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGendataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_vocals_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_samples_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgendata_test_vocals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m#Y_test[0:n_samples_test,1] = gendata_test_vocals.Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\testingspectrogram\\gendataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, user_dir, contains_vocals, n_samples)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# These are dimensions of the matrix [X, Y]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# This will ensure we are indexing correctly to put the x for our sample into our X matrix of all songs' data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    " import numpy as np\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "# from keras.optimizers import SGD\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "from gendataset import Gendataset\n",
    "from spectrogram import Spectrogram\n",
    "import os\n",
    "\n",
    "train_vocals_dir = \"C:/Users/numbe/Documents/Academics/Coursework/CS 129 - Machine Learning/Final Project/musdb18/train/Vocal Versions\"\n",
    "train_no_vocals_dir = \"C:/Users/numbe/Documents/Academics/Coursework/CS 129 - Machine Learning/Final Project/musdb18/train/Instrumental Versions\"\n",
    "test_vocals_dir = \"C:/Users/numbe/Documents/Academics/Coursework/CS 129 - Machine Learning/Final Project/musdb18/test/Vocal Versions\"\n",
    "test_no_vocals_dir = \"C:/Users/numbe/Documents/Academics/Coursework/CS 129 - Machine Learning/Final Project/musdb18/test/Instrumental Versions\"\n",
    "\n",
    "\n",
    "# Generate full train set\n",
    "\n",
    "n_samples_train = 46200\n",
    "X_train = np.zeros((2*n_samples_train, 513, 23))\n",
    "Y_train = np.zeros((2*n_samples_train, 1))\n",
    "\n",
    "gendata_train_vocals = Gendataset(train_vocals_dir, True, n_samples_train)\n",
    "X_train[0:n_samples_train,:,:] = gendata_train_vocals.X\n",
    "Y_train[0:n_samples_train,1] = gendata_train_vocals.Y\n",
    "\n",
    "gendata_train_no_vocals = Gendataset(train_no_vocals_dir, False, n_samples_train)\n",
    "X_train[n_samples_train:,:,:] = gendata_train_no_vocals.X\n",
    "Y_train[n_samples_train:, 1] = gendata_train_no_vocals.Y \n",
    "\n",
    "# Can make this more efficient by just generating one large empty matrix ~[X, Y] with a total \n",
    "# number of rows twice that of X or Y and then shuffle it, and then separate out X_train and Y_train\n",
    "# but first would have to make X unrolled...\n",
    "\n",
    "# X_train_unshuffled = (np.concatenate((X_train_vocals, X_train_no_vocals), axis=0))\n",
    "# Y_train_unshuffled = (np.concatenate((Y_train_vocals, Y_train_no_vocals), axis=0))\n",
    "# Matrix_train = np.random.shuffle(np.concatenate((X_train_unshuffled, Y_train_unshuffled), axis=1))\n",
    "\n",
    "# X_train = Matrix_train[:,:-1]\n",
    "# print(X_train.shape)\n",
    "# Y_train = Matrix_train[:,Matrix_train.shape[1]-1]\n",
    "# print(Y_train.shape)\n",
    "\n",
    "# # Generate full test set\n",
    "\n",
    "n_samples_test = 24505\n",
    "X_test = np.zeros((2*n_samples_test, 513, 23))\n",
    "#Y_test = np.zeros((2*n_samples_test, 1))\n",
    "Y_test = np.zeros((2*n_samples_test))\n",
    "\n",
    "gendata_test_vocals = Gendataset(test_vocals_dir, True, n_samples_test)\n",
    "X_test[0:n_samples_test,:,:] = gendata_test_vocals.X\n",
    "#Y_test[0:n_samples_test,1] = gendata_test_vocals.Y\n",
    "Y_test[0:n_samples_test] = gendata_test_vocals.Y\n",
    "\n",
    "gendata_test_no_vocals = Gendataset(test_no_vocals_dir, False , n_samples_test)\n",
    "X_test[n_samples_test:,:,:] = gendata_test_no_vocals.X\n",
    "#Y_test[n_samples_test:,1] = gendata_test_no_vocals.Y\n",
    "Y_test[n_samples_test:] = gendata_test_no_vocals.Y\n",
    "\n",
    "print(X_test_no_vocals.shape)\n",
    "print(X_test_vocals.shape)\n",
    "\n",
    "\n",
    "#spec = Spectrogram(\"Al James - Schoolboy Facination.stem.wav\", True)\n",
    "#x = spec.get_x()\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(16, (3, 3), padding='same', input_shape=(513, 23, 1)))\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64))\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss=keras.losses.binary_crossentropy, optimizer=sgd, metrics=['accuracy'])\n",
    "# model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train\n",
    "# del Y_train\n",
    "# #del Matrix_train\n",
    "del X_train_vocals \n",
    "del Y_train_vocals\n",
    "del X_train_no_vocals \n",
    "del Y_train_no_vocals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_unshuffled = (np.concatenate((X_train_vocals, X_train_no_vocals), axis=0))\n",
    "# Y_train_unshuffled = (np.concatenate((Y_train_vocals, Y_train_no_vocals), axis=0))\n",
    "# print(X_train_unshuffled.shape)\n",
    "# print(Y_train_unshuffled.shape)\n",
    "# Matrix_train = np.random.shuffle(np.concatenate((X_train_unshuffled, Y_train_unshuffled), axis=1))\n",
    "\n",
    "# X_train = Matrix_train[:,:-1]\n",
    "# print(X_train.shape)\n",
    "# Y_train = Matrix_train[:,Matrix_train.shape[1]-1]\n",
    "# print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng_state = np.random.get_state()\n",
    "# np.random.shuffle(X_train_unshuffled)\n",
    "# np.random.set_state(rng_state)\n",
    "# np.random.shuffle(Y_train_unshuffled)\n",
    "\n",
    "# print(X_train_unshuffled.shape)\n",
    "# print(Y_train_unshuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_unshuffled[0:10]\n",
    "X_train_unshuffled[0:10,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((2*n_samples_train, 513, 23))\n",
    "Y_train = np.zeros((2*n_samples_train)) #Change to Y_train = np.zeros((2*n_samples_train,1)) \n",
    "\n",
    "X_train[0:n_samples_train,:,:] = gendata_train_vocals.X\n",
    "Y_train[0:n_samples_train] = gendata_train_vocals.Y #Change to Y_train[0:n_samples_train,1] = gendata_train_vocals.Y\n",
    "X_train[n_samples_train:,:,:] = gendata_train_no_vocals.X\n",
    "Y_train[n_samples_train:] = gendata_train_no_vocals.Y #Change to Y_train[n_samples_train:,1] = gendata_train_no_vocals.Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
